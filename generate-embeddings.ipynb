{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('./src')\n",
    "from dataloaders import TileDataset\n",
    "from models import SimSiam, Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'simsiam'\n",
    "# epoch = '0999'\n",
    "# mpath = f'/mnt/data5/spatial/runs/{model_name}-all-slides/checkpoints/{epoch}.pt'\n",
    "# chkpt = torch.load(mpath)\n",
    "\n",
    "# model = SimSiam(\n",
    "#     backbone='resnet50',\n",
    "#     projector_hidden_dim=2048,\n",
    "#     predictor_hidden_dim=512,\n",
    "#     output_dim=2048,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'triplet'\n",
    "epoch = '0999'\n",
    "mpath = f'/mnt/data5/spatial/runs/{model_name}-all-slides/checkpoints/{epoch}.pt'\n",
    "chkpt = torch.load(mpath)\n",
    "\n",
    "model = Triplet(\n",
    "    backbone='resnet50',\n",
    "    projector_hidden_dim=2048,\n",
    "    output_dim=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(chkpt['state_dict'])\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TileDataset(\n",
    "    name='train',\n",
    "    tile_dirs=[\n",
    "        f'/mnt/data5/spatial/tiles/slide{slide}/{section}1'\n",
    "        for slide in [1, 2, 3, 4]\n",
    "        for section in ['A', 'B', 'C', 'D']\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Train Dataset Norm: 100%|██████████| 36896/36896 [00:31<00:00, 1179.08it/s]\n"
     ]
    }
   ],
   "source": [
    "mean, std = ds.get_mean_std()\n",
    "norm = T.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.39it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.69it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.69it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.89it/s]\n",
      "100%|██████████| 17/17 [00:04<00:00,  4.07it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.27it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  4.41it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = {}\n",
    "count = 0\n",
    "for slide in [1, 2, 3, 4]:\n",
    "    for section in ['A', 'B', 'C', 'D']:\n",
    "        eval_section = f'slide{slide}/{section}1'\n",
    "        cols = [\n",
    "            \"barcode\",\n",
    "            \"in_tissue\",\n",
    "            \"array_row\",\n",
    "            \"array_col\",\n",
    "            \"pxl_row_in_fullres\",\n",
    "            \"pxl_col_in_fullres\",\n",
    "        ]\n",
    "        pos_df = pd.read_csv(\n",
    "            os.path.join('/mnt/data5/spatial/count', eval_section, 'outs/spatial/tissue_positions_list.csv'),\n",
    "            header=None,\n",
    "            names=cols,\n",
    "        )\n",
    "        pos_df = pos_df[pos_df['in_tissue'] == 1].reset_index(drop=True)\n",
    "        count += len(pos_df)\n",
    "\n",
    "        eval_tile_dir = os.path.join('/mnt/data5/spatial/tiles', eval_section)\n",
    "        eval_ds = TileDataset(\n",
    "            name=eval_section,\n",
    "            tile_dirs=[eval_tile_dir],\n",
    "            transform=lambda ds, idx, x: norm(x),\n",
    "        )\n",
    "\n",
    "        # use the ordering of the tiles in the metadata\n",
    "        new_tile_paths = eval_tile_dir + '/' + pos_df['barcode'] + '.png'\n",
    "        ntps = new_tile_paths.sort_values().reset_index(drop=True)\n",
    "        otps = pd.Series(eval_ds.tile_paths).sort_values().reset_index(drop=True)\n",
    "        # check that actual tiles match metadata\n",
    "        assert ntps.equals(otps)\n",
    "        eval_ds.tile_paths = new_tile_paths\n",
    "\n",
    "        eval_dl = DataLoader(\n",
    "            eval_ds,\n",
    "            batch_size=256,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        embeddings = []\n",
    "        for eval_step, tiles in enumerate(tqdm(eval_dl)):\n",
    "            tiles = tiles.to('cuda')\n",
    "            with torch.no_grad():\n",
    "                embedding = model.encoder(tiles).to('cpu')\n",
    "                embeddings.append(embedding)\n",
    "        all_embeddings[eval_section] = torch.concatenate(embeddings, axis=0)\n",
    "\n",
    "assert count == len(ds.tile_paths)\n",
    "\n",
    "os.makedirs(f'/mnt/data5/spatial/embeddings/{model_name}-all-slides-{epoch}', exist_ok=True)\n",
    "torch.save(all_embeddings, f'/mnt/data5/spatial/embeddings/{model_name}-all-slides-{epoch}/embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
